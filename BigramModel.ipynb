{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### In this project we are making character based model which predicts the next character based on previous text"
      ],
      "metadata": {
        "id": "ysgfDnc-ZW9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using tine shakespere dataset where we have all the poems written by shakespere in text document format\n"
      ],
      "metadata": {
        "id": "ayt_oHxkXkkP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCvSejakXTBK",
        "outputId": "551ee0ac-8b95-453f-de7e-eba57a619a75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-04 19:07:46--  https://raw.githubusercontent.com/Karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.2’\n",
            "\n",
            "\rinput.txt.2           0%[                    ]       0  --.-KB/s               \rinput.txt.2         100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-04-04 19:07:46 (17.3 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Downloading tiny shakespere dataset\n",
        "!wget https://raw.githubusercontent.com/Karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## reading the text file\n",
        "with open('input.txt','r',encoding='utf-8') as f:\n",
        "  text=f.read()"
      ],
      "metadata": {
        "id": "LEg6ugRiYFXm"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \",len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QjRpyK7YaHq",
        "outputId": "d64261da-3167-448e-af42-968f8bea9506"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## first 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w13mCBqYkPL",
        "outputId": "afb5f956-34fd-4fc5-c225-2c4297fe8b4d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## here are all the unique characters that occur in the text\n",
        "\n",
        "## text -> sequece of char , set -> find unique char, list -> make list\n",
        "chars=sorted(list(set(text)))\n",
        "\n",
        "vocab_size=len(chars)\n",
        "\n",
        "print(\"Unique character in this text are : \",''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abeeEoP0YvEK",
        "outputId": "82f6bb41-df27-4437-be30-3d42023da2db"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique character in this text are :  \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## create a mapping from character to integer"
      ],
      "metadata": {
        "id": "aClY6RyjsGyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## stoi is dictnary having elements as character:index\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "\n",
        "## itos is dictnary having elements as index:character\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "\n",
        "## function to convert every character in string to it desired index acc to stoi and returns list\n",
        "encode = lambda s: [stoi[i] for i in s]\n",
        "\n",
        "## function to convert every index in list to it desired character and return a string\n",
        "decode = lambda s: ''.join([itos[index] for index in s])\n",
        "\n",
        "print(encode(\"hello world\"))\n",
        "print(decode(encode(\"hello world\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bln7zxfFaNF-",
        "outputId": "0f1d7a15-3d7f-481d-adb9-e8b3201f1bcc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42]\n",
            "hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode the entire text of shakespeare poem and store it into torch.tensor"
      ],
      "metadata": {
        "id": "nphOylq4z8Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data=torch.tensor(encode(text),dtype=torch.long)\n",
        "print(\"length of data (encoded text file) :\",len(data))\n",
        "print(\"Shape of data (encoded text file) : \",data.shape)\n",
        "print(\"dtatype of data (encoded text file) :\",data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm4mnnWGu01w",
        "outputId": "a350005b-ae63-41e9-e399-ccf4ba87af46"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of data (encoded text file) : 1115394\n",
            "Shape of data (encoded text file) :  torch.Size([1115394])\n",
            "dtatype of data (encoded text file) : torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## split the data into traning and testing\n",
        "\n",
        "Note : we can't use train test split library because we have sequential data where sequence matters"
      ],
      "metadata": {
        "id": "5yX_h6Rv2pJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## taking first 90% data for training and rest data for testing\n",
        "n=int(0.9*len(data))\n",
        "train_data=data[:n]\n",
        "test_data=data[n:]"
      ],
      "metadata": {
        "id": "m3lhOB4j0wvX"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## defining block size to send to model for training\n",
        "block_size=8\n",
        "\n",
        "## defining sample training and testing data with their context and target integer\n",
        "x=train_data[:block_size]\n",
        "y=train_data[1:block_size+1]\n",
        "\n",
        "print(\"sample training data \",x)\n",
        "print(\"sample testing data \",y)\n",
        "\n",
        "## printing how the dataset will look like\n",
        "for t in range(block_size):\n",
        "  context= x[:t+1]\n",
        "  target= y[t]\n",
        "  print(\"when context is \",context,\" the target is \",target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjoiFble3PQe",
        "outputId": "c83c2e45-5501-4329-b8dc-05c1d9507d75"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample training data  tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
            "sample testing data  tensor([47, 56, 57, 58,  1, 15, 47, 58])\n",
            "when context is  tensor([18])  the target is  tensor(47)\n",
            "when context is  tensor([18, 47])  the target is  tensor(56)\n",
            "when context is  tensor([18, 47, 56])  the target is  tensor(57)\n",
            "when context is  tensor([18, 47, 56, 57])  the target is  tensor(58)\n",
            "when context is  tensor([18, 47, 56, 57, 58])  the target is  tensor(1)\n",
            "when context is  tensor([18, 47, 56, 57, 58,  1])  the target is  tensor(15)\n",
            "when context is  tensor([18, 47, 56, 57, 58,  1, 15])  the target is  tensor(47)\n",
            "when context is  tensor([18, 47, 56, 57, 58,  1, 15, 47])  the target is  tensor(58)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Macking batches of input data"
      ],
      "metadata": {
        "id": "NbJtoRzDMyT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## setting seed so that random number so generated is same\n",
        "torch.manual_seed(1337)\n",
        "batch_size=4 ## we try to send 4 batches to model for training\n",
        "block_size=8 ## define the context length\n",
        "\n",
        "## function to genrate a small batch of data of inputs x and target y\n",
        "def get_batch(split):\n",
        "  data = train_data if split==\"train\" else test_data\n",
        "  ix=torch.randint(len(data)-block_size,(batch_size,))\n",
        "  x=torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x,y\n",
        "\n",
        "xb,yb=get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('target')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print(\"-------\")\n",
        "\n",
        "for b in range(batch_size):\n",
        "  for t in range(block_size):\n",
        "    context=xb[b,:t+1]    ## since in xb is tensor so if would be list it would be similar to xb[b[:t+1]]\n",
        "    target=yb[b,t]\n",
        "    print(\"when input is \",context,\" the target is \",target)"
      ],
      "metadata": {
        "id": "X_nKRTqD5qNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd21e30-7152-47d5-aed6-2dd26cd0d8cf"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "target\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "-------\n",
            "when input is  tensor([24])  the target is  tensor(43)\n",
            "when input is  tensor([24, 43])  the target is  tensor(58)\n",
            "when input is  tensor([24, 43, 58])  the target is  tensor(5)\n",
            "when input is  tensor([24, 43, 58,  5])  the target is  tensor(57)\n",
            "when input is  tensor([24, 43, 58,  5, 57])  the target is  tensor(1)\n",
            "when input is  tensor([24, 43, 58,  5, 57,  1])  the target is  tensor(46)\n",
            "when input is  tensor([24, 43, 58,  5, 57,  1, 46])  the target is  tensor(43)\n",
            "when input is  tensor([24, 43, 58,  5, 57,  1, 46, 43])  the target is  tensor(39)\n",
            "when input is  tensor([44])  the target is  tensor(53)\n",
            "when input is  tensor([44, 53])  the target is  tensor(56)\n",
            "when input is  tensor([44, 53, 56])  the target is  tensor(1)\n",
            "when input is  tensor([44, 53, 56,  1])  the target is  tensor(58)\n",
            "when input is  tensor([44, 53, 56,  1, 58])  the target is  tensor(46)\n",
            "when input is  tensor([44, 53, 56,  1, 58, 46])  the target is  tensor(39)\n",
            "when input is  tensor([44, 53, 56,  1, 58, 46, 39])  the target is  tensor(58)\n",
            "when input is  tensor([44, 53, 56,  1, 58, 46, 39, 58])  the target is  tensor(1)\n",
            "when input is  tensor([52])  the target is  tensor(58)\n",
            "when input is  tensor([52, 58])  the target is  tensor(1)\n",
            "when input is  tensor([52, 58,  1])  the target is  tensor(58)\n",
            "when input is  tensor([52, 58,  1, 58])  the target is  tensor(46)\n",
            "when input is  tensor([52, 58,  1, 58, 46])  the target is  tensor(39)\n",
            "when input is  tensor([52, 58,  1, 58, 46, 39])  the target is  tensor(58)\n",
            "when input is  tensor([52, 58,  1, 58, 46, 39, 58])  the target is  tensor(1)\n",
            "when input is  tensor([52, 58,  1, 58, 46, 39, 58,  1])  the target is  tensor(46)\n",
            "when input is  tensor([25])  the target is  tensor(17)\n",
            "when input is  tensor([25, 17])  the target is  tensor(27)\n",
            "when input is  tensor([25, 17, 27])  the target is  tensor(10)\n",
            "when input is  tensor([25, 17, 27, 10])  the target is  tensor(0)\n",
            "when input is  tensor([25, 17, 27, 10,  0])  the target is  tensor(21)\n",
            "when input is  tensor([25, 17, 27, 10,  0, 21])  the target is  tensor(1)\n",
            "when input is  tensor([25, 17, 27, 10,  0, 21,  1])  the target is  tensor(54)\n",
            "when input is  tensor([25, 17, 27, 10,  0, 21,  1, 54])  the target is  tensor(39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using bigram language model"
      ],
      "metadata": {
        "id": "HcF6rbMZs0Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_MtKUU0Osw1",
        "outputId": "374b2e9f-071f-497c-9f04-feb7aeb3807d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table=nn.Embedding(vocab_size,vocab_size)\n",
        "\n",
        "  def forward(self,idx,targets=None):\n",
        "    ## idx and target are both (B,T) tensor of integrs\n",
        "    logists=self.token_embedding_table(idx) ## (B,T,C)\n",
        "\n",
        "    if targets is None:\n",
        "      loss=None\n",
        "    else:\n",
        "      B,T,C =logists.shape\n",
        "      logists=logists.view(B*T,C)\n",
        "      targets=targets.view(-1)\n",
        "      loss=F.cross_entropy(logists,targets)\n",
        "\n",
        "    return logists, loss\n",
        "\n",
        "  def generate(self,idx,max_new_token):\n",
        "    ## idx is (B,T) array of indices in the current context\n",
        "    for _ in range(max_new_token):\n",
        "      ## get the predictions\n",
        "      logists, loss=self(idx)\n",
        "      ## focus only on the last time step\n",
        "      logists = logists[:,-1,:] ## becomes (B,C)\n",
        "      probs=F.softmax(logists, dim=1) #(B,C)\n",
        "      # sample from the distribution\n",
        "      idx_next=torch.multinomial(probs,num_samples=1) # (B,1)\n",
        "      ## append sampled index to the running sequence\n",
        "      idx=torch.cat((idx,idx_next),dim=1) # (B,T+1)\n",
        "    return idx\n",
        "\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logists,loss= m.forward(xb,yb)\n",
        "print(logists.shape)\n",
        "print(loss)\n",
        "\n",
        "idx=torch.zeros((1,1),dtype=torch.long)\n",
        "print(decode(m.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_token=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjV6YwOAV9bg",
        "outputId": "2f2076b8-005c-4e00-f103-aa709b914de5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Brief explaination about terms B,T,C\n",
        "B -> batch size (here 32)\n",
        "\n",
        "T -> time step or block size (here 8)\n",
        "\n",
        "C -> channel or vocab size or size of embedding vector (here 65)\n",
        "\n",
        "Note : here in forward fucntion of BigramModel the logits and target are flattend because we are using cross validation frunction for calculating loss so this cross validation function expect :\n",
        "\n",
        "1. logits (input) as a 2d vector (N,C) where N->tokens and C-> no. of classes(here vocab size)\n",
        "so we flatten logits from shape (B,T,C) to (B*T,C)\n",
        "\n",
        "2. target as 1d vector (N) were N->token\n",
        "so we flatten target from shape (B,T) to (B*T)\n",
        "\n",
        "here B*T represent all the token in single line since B(Batch_Size) * T(block_size)"
      ],
      "metadata": {
        "id": "RC0JToWaXVtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDhMJvnYWknn",
        "outputId": "4b2d12d4-c583-4e75-8c62-85a8f468f876"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
              "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
              "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
              "        [25, 17, 27, 10,  0, 21,  1, 54]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joyBzyD0WlyX",
        "outputId": "effa4c7c-e6cc-4e10-c97d-cf6d795bfb5f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
              "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
              "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
              "        [17, 27, 10,  0, 21,  1, 54, 39]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Using AdmaW optimizer in pytorch here m.parameter()-> passes all the trainable parameter to optimiser AND lr -> learning rate\n",
        "optimizer=torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "hUPQmdRpvf8b"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## note : the more we run this codeblock more the loss will be minimised\n",
        "\n",
        "## minimising the loss\n",
        "batch_size=32\n",
        "\n",
        "## range is similar to epoch in tensorflow\n",
        "for steps in range(1000):\n",
        "\n",
        "  # sample a batch of data\n",
        "  xb,yb=get_batch('train')\n",
        "\n",
        "  #evaluate the loss by passing x_train and y_train to model\n",
        "  logists,loss=m(xb,yb)\n",
        "  # zero out the gradient\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  # compute gradient\n",
        "  loss.backward()\n",
        "  # update model parameter\n",
        "  optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ],
      "metadata": {
        "id": "A1Mg85NtwIsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03626491-aea0-4b7e-a0c0-56966e1b237e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7218432426452637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## now after minimising the loss if again try model to print next character for the character embedded as zero -> it gives better result\n",
        "print(decode(m.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_token=100)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qfpQq1_aAqX",
        "outputId": "f4c75b9e-4212-4f1e-809a-12da3955982c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "olylvLLko'TMyatyIoconxad.?-tNSqYPsx&bF.oiR;BD$dZBMZv'K f bRSmIKptRPly:AUC&$zLK,qUEy&Ay;ZxjKVhmrdagC-\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note  : print(decode(m.generate(idx=torch.zeros((1,1),dtype=torch.long),max_new_token=100)[0].tolist()))\n",
        "\n",
        "this line means :\n",
        " - Starting with a blank/zero token\n",
        " - Asking the model \"what character should come next?\" 100 times\n",
        " - Converting the resulting sequence of token IDs back to readable text"
      ],
      "metadata": {
        "id": "l7t0I2R8bkIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Note**: till here we have build a very simple model which predicts what comes next based on the last character of context being provided to model"
      ],
      "metadata": {
        "id": "7wmPErfDcI5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self attention blocks for procecessing tokens\n"
      ],
      "metadata": {
        "id": "FMKu4NCDKQZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## consider the following toy example\n",
        "\n",
        "## setting seed to get same result everytime\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 ## batch, time_step, channel\n",
        "x=torch.randn(B,T,C) ## random initialisation of tensor x with shape(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFITVU13amt0",
        "outputId": "33bdc1c3-f841-4359-c272-9458ef32a58a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## note : here the concept we are using to getnext character is\n",
        "\n",
        "for predicting the next character we just take average of all the charater appearing before the current character to predict the next character"
      ],
      "metadata": {
        "id": "64E2N4FeZX_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 1 : Using appropriate for loop for getting average of each channel number with it above numbers"
      ],
      "metadata": {
        "id": "yeC4mN-ioEdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## initialising a tensor named xbow filled dwith zeros of shape (B,T,C)\n",
        "xbow=torch.zeros((B,T,C))\n",
        "\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    ## collecting the previous token from current token\n",
        "    xprev=x[b,:t+1] ## (t,C)\n",
        "    ## adding the average till the current term in xbow\n",
        "    xbow[b,t]=torch.mean(xprev,0)"
      ],
      "metadata": {
        "id": "1_jxiKkRZQXW"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxXkeRslNNc",
        "outputId": "0a1092e6-a429-4aca-efe5-82c5b824e00d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.3596, -0.9152],\n",
              "        [ 0.6258,  0.0255],\n",
              "        [ 0.9545,  0.0643],\n",
              "        [ 0.3612,  1.1679],\n",
              "        [-1.3499, -0.5102],\n",
              "        [ 0.2360, -0.2398],\n",
              "        [-0.9211,  1.5433]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTO2LjDiqx89",
        "outputId": "b4f528b5-2acc-44a2-8c75-fe09932a3788"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we can see 1st row remains same but 2nd row is average of 1st and 2nd row\n",
        "similaty 3rd row is of 1sr,2nd,3rd\n",
        "\n",
        "note: since B=4, T=8 and C=2 so average is taken among its own channel\n",
        "\n",
        "example in 3rd row [a b]\n",
        "\n",
        "where a = 0.1808 + (-0.0894) + 0.1490 / 3\n",
        "\n",
        "and b= (-0.0700) + (-0.4926) + (-0.3199) /3"
      ],
      "metadata": {
        "id": "6LfAHQiNq1Qt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## by using\n",
        "    ## collecting the previous token from current token\n",
        "    xprev=x[b,:t+1] ## (t,C)\n",
        "    ## adding the average till the current term in xbow\n",
        "    xbow[b,t]=torch.mean(xprev,0)\n",
        "\n",
        "we get xbow which has average of each channel number with it above numbers\n",
        "\n"
      ],
      "metadata": {
        "id": "rUjLMKVwnXvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 2 : Using matrix multiplication to get average of each channel number with it above numbers"
      ],
      "metadata": {
        "id": "auOsXLXs6oQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## code for simple matrix multiplication in pytorch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# a=torch.ones(3,3)  ## makea matrix 3X3 of all elemnt zero\n",
        "a = torch.tril(torch.ones(3,3)) ## makes lower traingular matrix\n",
        "b = torch.randint(0,10,(3,2)).float()  ## generare (3X2) matrix of random number 0 - 10 as type float number\n",
        "\n",
        "c = a @ b  ## matrix multiplication of tensor object\n",
        "\n",
        "print('a=')\n",
        "print(a)\n",
        "print('------')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('------')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "id": "VxJPID6iqzyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51908b9-66cc-43ac-aaa5-1519fce2e268"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1., 0., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 1.]])\n",
            "------\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "------\n",
            "c=\n",
            "tensor([[ 2.,  7.],\n",
            "        [ 8., 11.],\n",
            "        [14., 16.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### now we are aiming to get average of each channel number in b with it above numbers and showing output in c\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3,3)) ## makes lower traingular matrix\n",
        "\n",
        "a= a/torch.sum(a,1,keepdim=True) ## normalise the row of a\n",
        "\n",
        "b = torch.randint(0,10,(3,2)).float()  ## generare (3X2) matrix of random number 0 - 10 as type float number\n",
        "\n",
        "c = a @ b  ## matrix multiplication of tensor object\n",
        "\n",
        "print('a=')\n",
        "print(a)\n",
        "print('------')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('------')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT9HjBI38H1i",
        "outputId": "22088e0e-77b0-4155-c6d4-93ee9ccc1dcb"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "------\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "------\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so in this way by normalising the rows of 'a' we can get average of each channel number in b with it above numbers and showing output in c\n",
        "\n",
        "below is the way where we generate weights (used while training the model) and multiply it with x (randomly generated tensor of shape (B,T,C) )"
      ],
      "metadata": {
        "id": "CAZOPKby8mXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## weights (lower triangular matrix)\n",
        "weights=torch.tril(torch.ones(T,T))\n",
        "## normalise the matrix\n",
        "weights=weights/torch.sum(weights,1,keepdim=True)\n",
        "\n",
        "## matrix multiplication in pytorch\n",
        "xbow2=weights @ x ## here dim of weights = (T,T) but dim of x = (B,T,C)\n",
        "## so since weight is tensor object so it will automatically adjust its dim to (B,T,C)\n",
        "\n",
        "xbow2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QS06qLy8kai",
        "outputId": "dd9b81b3-1aff-4343-abc5-fa4216b5eee7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## note xbow and xbow2 are same, they are only generated in different ways"
      ],
      "metadata": {
        "id": "s9pZrqFCqAGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## they are same\n",
        "print(xbow[0])\n",
        "print(xbow2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v6ySK5Hp9aa",
        "outputId": "87323c3f-2eb3-45ce-874a-265dc7e5dbed"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n",
            "tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 3 : Using softmax function"
      ],
      "metadata": {
        "id": "1HjrzvL9qoZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## make lower triangular matrix\n",
        "tril=torch.tril(torch.ones(T,T))\n",
        "tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWGmkMOcqS2z",
        "outputId": "f3cb5cc4-1982-40b2-8bc0-139350958484"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## make initial weights as zeros\n",
        "weight=torch.zeros((T,T))\n",
        "weight\n",
        "## it shows it interaction strength or affinity ie, how much from the past we want to aggregate and average up"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ6fZGH5UUIE",
        "outputId": "bd09ea3a-66cd-49f4-efc7-acd388f24630"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## it will make zeros in lower triangular matrix to -infinity and 1s to zeros\n",
        "weight=weight.masked_fill(tril==0,float('-inf'))\n",
        "weight\n",
        "## this line show tokens from the past can't communicate by setting them to -infinity we are saying that we will not aggregate anything from those token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CZLWhhVU8XL",
        "outputId": "a791054f-8f93-4cc6-855c-19bbe984ff3f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
              "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
              "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
              "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
              "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
              "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## using softmax function : softmax function act a normalisation which make sum of tokens in a row as 1\n",
        "weight=F.softmax(weight,dim=-1)\n",
        "weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2afQYJgGXdT3",
        "outputId": "3f0e9dfc-2ece-4da9-ae98-72e3e52afd98"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow3=weight @ x\n",
        "xbow3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2rchijYX2te",
        "outputId": "df947a29-5313-4497-c8a1-72dd5e320bd0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]],\n",
              "\n",
              "        [[-0.6631, -0.2513],\n",
              "         [ 0.1735, -0.0649],\n",
              "         [ 0.1685,  0.3348],\n",
              "         [-0.1621,  0.1765],\n",
              "         [-0.2312, -0.0436],\n",
              "         [-0.1015, -0.2855],\n",
              "         [-0.2593, -0.1630],\n",
              "         [-0.3015, -0.2293]],\n",
              "\n",
              "        [[ 1.6455, -0.8030],\n",
              "         [ 1.4985, -0.5395],\n",
              "         [ 0.4954,  0.3420],\n",
              "         [ 1.0623, -0.1802],\n",
              "         [ 1.1401, -0.4462],\n",
              "         [ 1.0870, -0.4071],\n",
              "         [ 1.0430, -0.1299],\n",
              "         [ 1.1138, -0.1641]]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## note: xbow, xbow2 and xbow3 are all same only they are generated using different methods"
      ],
      "metadata": {
        "id": "2ArVPmf6ZIn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"first batch of xbow\")\n",
        "print(xbow[0])\n",
        "print(\"first batch of xbow2\")\n",
        "print(xbow2[0])\n",
        "print(\"first batch of xbow3\")\n",
        "print(xbow3[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqK484wNZHpo",
        "outputId": "4951bb72-0361-4884-8338-c3799ffd7176"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first batch of xbow\n",
            "tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n",
            "first batch of xbow2\n",
            "tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n",
            "first batch of xbow3\n",
            "tensor([[ 0.1808, -0.0700],\n",
            "        [-0.0894, -0.4926],\n",
            "        [ 0.1490, -0.3199],\n",
            "        [ 0.3504, -0.2238],\n",
            "        [ 0.3525,  0.0545],\n",
            "        [ 0.0688, -0.0396],\n",
            "        [ 0.0927, -0.0682],\n",
            "        [-0.0341,  0.1332]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method 4 : Self Attention"
      ],
      "metadata": {
        "id": "l_vorJh2rnte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## earlier approach\n",
        "\n",
        "## make lower triangular matrix\n",
        "tril=torch.tril(torch.ones(T,T))\n",
        "## make initial weights as zeros\n",
        "weight=torch.zeros((T,T))\n",
        "## it shows it interaction strength or affinity ie, how much from the past we want to aggregate and average up\n",
        "## it will make zeros in lower triangular matrix to -infinity and 1s to zeros\n",
        "weight=weight.masked_fill(tril==0,float('-inf'))\n",
        "## this line show tokens from the past can't communicate by setting them to -infinity we are saying that we will not aggregate anything from those token\n",
        "weight=F.softmax(weight,dim=-1)\n",
        "\n",
        "\n",
        "## till here we were just taking initial weights as zero which indicate there is no relation between the currently predicted value and previous value that's why we get uniform matrix after applying softmax function\n",
        "\n",
        "## BUT WE KNOW IN SEQUENTIAL DATA THE NEXT PREDICTED VALUE DEPENDS ON PREVIOUS VALUE ALSO DIFFERNT WORDS IN PAST CORRELATE DIFFERENTLY WITH THE CURRENT WORD\n",
        "\n",
        "## SO WE NEED NEXT DATA SHOULD BE DEPENDENT ON CURRENT DATA THIS PROBLEM IS SOLVED BY SELF ATTENTION\n",
        "\n",
        "## in self attention each token of a sequence have two vector \"query vector\" and \"key vector\" where query vector tell what i am loking for and key vector say what do i contain\n",
        "## to find affifnity between the tokens or we can s which all token align with current token we find dot product of current query vector will all of the key vector of token present in sequence, the key vector getting very high amount in dot product align more with that query vector"
      ],
      "metadata": {
        "id": "-GfNJFjdZlKL"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C=4,8,32 ## batch,total token in sequence,channel (embedding dimension)\n",
        "x=torch.randn(B,T,C)"
      ],
      "metadata": {
        "id": "vQvVPLK8R55O"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### head of self attention\n",
        "head_size=16 ## a hyperparameter\n",
        "\n",
        "## key and query are used to convert are the input x (B,T,C) to output y (B,T,head_size)\n",
        "key = nn.Linear(C,head_size,bias=False)\n",
        "query = nn.Linear(C,head_size,bias=False)\n",
        "value=nn.Linear(C,head_size,bais=False)\n",
        "\n",
        "## making k(key) and q(query) for each input x\n",
        "k=key(x)\n",
        "q=query(x)\n",
        "\n",
        "## calculating weight\n",
        "weight= q @ k.transpose(-2,-1) ## (B,T,16) @ (B,16,T) ---> (B,T,T)\n",
        "## so for every input sequence we will have T X T matrix which represent the affinities\n",
        "\n",
        "## using self attenstion to genrate weights\n",
        "tril=torch.tril((torch.ones(T,T)))\n",
        "weight=weight.masked_fill(tril==0),float('-inf')\n",
        "weight=F.softmax(weights,dim=-1)\n",
        "\n",
        "\n",
        "v=value(x)\n",
        "output=weight @ v\n",
        "\n",
        "## important\n",
        "## key and query : reprsent what we are interrested in\n",
        "## x : represnt what we have\n",
        "## v : represent the vector so that selected after dot product of volleyball\n",
        "\n",
        "\n",
        "output.shape"
      ],
      "metadata": {
        "id": "6pBcwFYIqewp"
      },
      "execution_count": 74,
      "outputs": []
    }
  ]
}